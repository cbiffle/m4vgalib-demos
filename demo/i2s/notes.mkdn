The codec flips out if its data stream is interrupted, i.e. if the I2S master
stalls *at* *all*.  I had foolishly expected it to behave like most DACs and
hold the last output level, hiding stalls.  Nope.

I was initially getting stalls because of the video-related interrupts.  I'm
running the codec at 48kHz, which is probably too aggressive -- that's four
samples per scanline (ish) at 800x600, virtually requiring samples during
scanout.

One option would be to generate audio in lockstep with the scanout.  However,
because the I2S unit itself has no buffer, that'd limit us to about 14kHz
update rate: either left or right produced during hblank.  (28kHz would require
a sample during the middle of the line.)

Or, of course, mono.

Using the DMA controller kind of side-steps all this, of course.  The overall
throughput is minimal -- it's just latency-sensitive.  With DMA, we could
generate N samples during hblank, and allow them to spool out during scanout.

The I2S units are on APB1, so we'd use DMA1.  As long as the samples get
buffered in SRAM1, there are no conflicts with scanout.  (SRAM3 on the 42x
parts would also be fine.)

At 48kHz (say), we need a sample (either left or right) every 10.416 us.
With a 26.4 us scanline, that means 2.53 samples/scanline, or either 2 or 3.
That requires just six bytes of RAM for buffer, but requires compute during
hblank.

If we prepare data at vblank instead, we have to produce 1591.6 samples to keep
the pipeline full through the frame, or 3,184 bytes.  Still doable, if a bit
more expensive.

Preparing data at vblank will have advantages for stateful filters, I suspect.
They'd be able to carry state in registers for longer without spilling to RAM,
potentially reducing compute/sample.  In general, it would reduce entry/exit
costs.


Here's a strawman framework:

 - Play a sequence, like a player piano.
 - A sequence consists of sounds.
 - Each sound starts at a frame boundary and runs for an integral number of
   frames (possibly determined dynamically).
 - The sequence is sorted by start frame.
 - So at each frame boundary, we have some sounds ending, some sounds
   continuing, and some sounds starting.
 - Add the sound samples together and saturate to choose an output level.


